{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "20210823B.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fe7bfb5",
        "outputId": "489a6531-8ac3-438e-8051-8359ea14f7b0"
      },
      "source": [
        "pip install transformers"
      ],
      "id": "3fe7bfb5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.9.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygQU-FEZf052"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "id": "ygQU-FEZf052",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fukxbRIQf98i",
        "outputId": "24c558c0-3e67-4e79-8c07-2cdbc2e44bad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "fukxbRIQf98i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I5BHR8egh78X",
        "outputId": "19c65cff-c68b-45fc-f682-1d4c938408cd"
      },
      "source": [
        "!unzip drive/MyDrive/MSR_data/MSR_Project_files.zip"
      ],
      "id": "I5BHR8egh78X",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  drive/MyDrive/MSR_data/MSR_Project_files.zip\n",
            "replace __MACOSX/._MSR Project files ? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: __MACOSX/._MSR Project files   \n",
            "  inflating: MSR Project files /VerifiedDataLabels.csv  \n",
            "  inflating: __MACOSX/MSR Project files /._VerifiedDataLabels.csv  \n",
            "  inflating: MSR Project files /url_df.csv  \n",
            "  inflating: __MACOSX/MSR Project files /._url_df.csv  \n",
            "  inflating: MSR Project files /.DS_Store  \n",
            "  inflating: __MACOSX/MSR Project files /._.DS_Store  \n",
            "  inflating: MSR Project files /data_tensor_fnl  A\n",
            "\n",
            "  inflating: __MACOSX/MSR Project files /._data_tensor_fnl  \n",
            "  inflating: MSR Project files /stem_sentence_corpus  \n",
            "  inflating: __MACOSX/MSR Project files /._stem_sentence_corpus  \n",
            "  inflating: MSR Project files /I_tensor  \n",
            "  inflating: __MACOSX/MSR Project files /._I_tensor  \n",
            "  inflating: MSR Project files /df_csv_joined.csv  \n",
            "  inflating: __MACOSX/MSR Project files /._df_csv_joined.csv  \n",
            "  inflating: MSR Project files /MSR_text_2.csv  \n",
            "  inflating: __MACOSX/MSR Project files /._MSR_text_2.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHTB1Uc2CD-k",
        "outputId": "1716d230-60cb-4a49-ccbd-5075d64ebd64"
      },
      "source": [
        "!unzip drive/MyDrive/MSR_data/MSR_Project_files.zip > /dev/null"
      ],
      "id": "hHTB1Uc2CD-k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace __MACOSX/._MSR Project files ? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "b530e39b",
        "outputId": "2383bd30-d64d-477f-a08f-7fb7049af347"
      },
      "source": [
        "url_df_read = pd.read_csv('drive/MyDrive/MSR_data/url_df.csv', index_col=[0])\n",
        "url_df_read"
      ],
      "id": "b530e39b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/637...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/637...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1868</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1869</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1870</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1871</th>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1872 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               URL_link\n",
              "0     https://dq06ugkuram52.cloudfront.net/files/637...\n",
              "1     https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "2     https://dq06ugkuram52.cloudfront.net/files/637...\n",
              "3     https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "4     https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "...                                                 ...\n",
              "1867  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1868  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1869  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1870  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1871  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "\n",
              "[1872 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81142971",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d481bb47-b66d-4248-aa42-1311300066cf"
      },
      "source": [
        "MSR_df_read = pd.read_csv('drive/MyDrive/MSR_data/MSR_text_2.csv', index_col=[0])\n",
        "MSR_df_read"
      ],
      "id": "81142971",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10/19/2020\\n\\nSlavery and Human trafﬁcking | S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nModern Slav...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10/19/2020\\n\\nSlavery | Hall and Woodhouse\\n\\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Greene King | MODERN SLAVERY STATEMENT\\n\\nhttp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Charles Wells Ltd \\n \\nModern Slavery and Huma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1867</th>\n",
              "      <td>\\n\\n \\nModern Slavery Act 2015 Statement   \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1868</th>\n",
              "      <td>Upto 60% off + 20% off ends\\n\\n \\n\\n \\n\\nSearc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1869</th>\n",
              "      <td>\\n\\nSlavery and Human Trafficking Transparenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1870</th>\n",
              "      <td>Reward Gateway Slavery\\nand Human Trafficking\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1871</th>\n",
              "      <td>Modern Slavery Act Statement\\n– January 2021\\n...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1872 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   Text\n",
              "0     10/19/2020\\n\\nSlavery and Human trafﬁcking | S...\n",
              "1      \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nModern Slav...\n",
              "2     10/19/2020\\n\\nSlavery | Hall and Woodhouse\\n\\n...\n",
              "3     Greene King | MODERN SLAVERY STATEMENT\\n\\nhttp...\n",
              "4     Charles Wells Ltd \\n \\nModern Slavery and Huma...\n",
              "...                                                 ...\n",
              "1867   \\n\\n \\nModern Slavery Act 2015 Statement   \\n...\n",
              "1868  Upto 60% off + 20% off ends\\n\\n \\n\\n \\n\\nSearc...\n",
              "1869   \\n\\nSlavery and Human Trafficking Transparenc...\n",
              "1870  Reward Gateway Slavery\\nand Human Trafficking\\...\n",
              "1871  Modern Slavery Act Statement\\n– January 2021\\n...\n",
              "\n",
              "[1872 rows x 1 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d418a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "outputId": "97e7a7c9-c50f-44a0-f865-d875edc9834d"
      },
      "source": [
        "df_csv_joined = pd.read_csv('drive/MyDrive/MSR_data/df_csv_joined.csv')\n",
        "df_csv_joined"
      ],
      "id": "5d418a32",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer ID</th>\n",
              "      <th>Answer Page</th>\n",
              "      <th>Metric</th>\n",
              "      <th>Company</th>\n",
              "      <th>Value</th>\n",
              "      <th>Source Page</th>\n",
              "      <th>Text</th>\n",
              "      <th>URL_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6382834</td>\n",
              "      <td>https://wikirate.org/~6382834</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>S A Brain Company Ltd</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6375302</td>\n",
              "      <td>10/19/2020\\n\\nSlavery and Human trafﬁcking | S...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/637...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6368402</td>\n",
              "      <td>https://wikirate.org/~6368402</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Pension Protection Fund</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6355100</td>\n",
              "      <td>\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nModern Slav...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6380781</td>\n",
              "      <td>https://wikirate.org/~6380781</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Hall &amp; Woodhouse Limited</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6375083</td>\n",
              "      <td>10/19/2020\\n\\nSlavery | Hall and Woodhouse\\n\\n...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/637...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6364508</td>\n",
              "      <td>https://wikirate.org/~6364508</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Greene King</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6357513</td>\n",
              "      <td>Greene King | MODERN SLAVERY STATEMENT\\n\\nhttp...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6379525</td>\n",
              "      <td>https://wikirate.org/~6379525</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Charles Wells</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6354153</td>\n",
              "      <td>Charles Wells Ltd \\n \\nModern Slavery and Huma...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1713</th>\n",
              "      <td>7311793</td>\n",
              "      <td>https://wikirate.org/~7311793</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>ECO Animal Health Group Plc</td>\n",
              "      <td>0</td>\n",
              "      <td>https://wikirate.org/~7307585</td>\n",
              "      <td>\\n\\n \\nModern Slavery Act 2015 Statement   \\n...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1714</th>\n",
              "      <td>7310878</td>\n",
              "      <td>https://wikirate.org/~7310878</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Victoria Plum Limited</td>\n",
              "      <td>0</td>\n",
              "      <td>https://wikirate.org/~7307593</td>\n",
              "      <td>Upto 60% off + 20% off ends\\n\\n \\n\\n \\n\\nSearc...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>7310802</td>\n",
              "      <td>https://wikirate.org/~7310802</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Creagh Concrete Products Limited</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~7307608</td>\n",
              "      <td>\\n\\nSlavery and Human Trafficking Transparenc...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>7311831</td>\n",
              "      <td>https://wikirate.org/~7311831</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Reward Gateway (UK) Ltd</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~7307616</td>\n",
              "      <td>Reward Gateway Slavery\\nand Human Trafficking\\...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1717</th>\n",
              "      <td>7309810</td>\n",
              "      <td>https://wikirate.org/~7309810</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Origin Fertilisers</td>\n",
              "      <td>0</td>\n",
              "      <td>https://wikirate.org/~7307078</td>\n",
              "      <td>Modern Slavery Act Statement\\n– January 2021\\n...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1718 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Answer ID  ...                                           URL_link\n",
              "0       6382834  ...  https://dq06ugkuram52.cloudfront.net/files/637...\n",
              "1       6368402  ...  https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "2       6380781  ...  https://dq06ugkuram52.cloudfront.net/files/637...\n",
              "3       6364508  ...  https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "4       6379525  ...  https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "...         ...  ...                                                ...\n",
              "1713    7311793  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1714    7310878  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1715    7310802  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1716    7311831  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1717    7309810  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "\n",
              "[1718 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAStIi8JNeZm",
        "outputId": "649ba846-fc6b-4696-9a05-f4fc9fecfba0"
      },
      "source": [
        "short_list_1500=[]\n",
        "for i in range(len(df_csv_joined['Text'])):\n",
        "    length = len(df_csv_joined['Text'][i])\n",
        "    if length<2000:\n",
        "      short_list_1500.append(i)\n",
        "\n",
        "len(short_list_1500) "
      ],
      "id": "ZAStIi8JNeZm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "115"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "id": "KQ_ImSbQat09",
        "outputId": "1620223e-6798-40e5-c614-4d827ba070b0"
      },
      "source": [
        "df_csv_joined1 = df_csv_joined.drop(short_list_1500)\n",
        "df_csv_joined1"
      ],
      "id": "KQ_ImSbQat09",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Answer ID</th>\n",
              "      <th>Answer Page</th>\n",
              "      <th>Metric</th>\n",
              "      <th>Company</th>\n",
              "      <th>Value</th>\n",
              "      <th>Source Page</th>\n",
              "      <th>Text</th>\n",
              "      <th>URL_link</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6382834</td>\n",
              "      <td>https://wikirate.org/~6382834</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>S A Brain Company Ltd</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6375302</td>\n",
              "      <td>10/19/2020\\n\\nSlavery and Human trafﬁcking | S...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/637...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6368402</td>\n",
              "      <td>https://wikirate.org/~6368402</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Pension Protection Fund</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6355100</td>\n",
              "      <td>\\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\n \\n\\nModern Slav...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6380781</td>\n",
              "      <td>https://wikirate.org/~6380781</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Hall &amp; Woodhouse Limited</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6375083</td>\n",
              "      <td>10/19/2020\\n\\nSlavery | Hall and Woodhouse\\n\\n...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/637...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6364508</td>\n",
              "      <td>https://wikirate.org/~6364508</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Greene King</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6357513</td>\n",
              "      <td>Greene King | MODERN SLAVERY STATEMENT\\n\\nhttp...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6379525</td>\n",
              "      <td>https://wikirate.org/~6379525</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Charles Wells</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~6354153</td>\n",
              "      <td>Charles Wells Ltd \\n \\nModern Slavery and Huma...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/635...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1713</th>\n",
              "      <td>7311793</td>\n",
              "      <td>https://wikirate.org/~7311793</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>ECO Animal Health Group Plc</td>\n",
              "      <td>0</td>\n",
              "      <td>https://wikirate.org/~7307585</td>\n",
              "      <td>\\n\\n \\nModern Slavery Act 2015 Statement   \\n...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1714</th>\n",
              "      <td>7310878</td>\n",
              "      <td>https://wikirate.org/~7310878</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Victoria Plum Limited</td>\n",
              "      <td>0</td>\n",
              "      <td>https://wikirate.org/~7307593</td>\n",
              "      <td>Upto 60% off + 20% off ends\\n\\n \\n\\n \\n\\nSearc...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1715</th>\n",
              "      <td>7310802</td>\n",
              "      <td>https://wikirate.org/~7310802</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Creagh Concrete Products Limited</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~7307608</td>\n",
              "      <td>\\n\\nSlavery and Human Trafficking Transparenc...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1716</th>\n",
              "      <td>7311831</td>\n",
              "      <td>https://wikirate.org/~7311831</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Reward Gateway (UK) Ltd</td>\n",
              "      <td>1</td>\n",
              "      <td>https://wikirate.org/~7307616</td>\n",
              "      <td>Reward Gateway Slavery\\nand Human Trafficking\\...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1717</th>\n",
              "      <td>7309810</td>\n",
              "      <td>https://wikirate.org/~7309810</td>\n",
              "      <td>Walk Free Foundation+MSA whistleblowing mechan...</td>\n",
              "      <td>Origin Fertilisers</td>\n",
              "      <td>0</td>\n",
              "      <td>https://wikirate.org/~7307078</td>\n",
              "      <td>Modern Slavery Act Statement\\n– January 2021\\n...</td>\n",
              "      <td>https://dq06ugkuram52.cloudfront.net/files/730...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1603 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Answer ID  ...                                           URL_link\n",
              "0       6382834  ...  https://dq06ugkuram52.cloudfront.net/files/637...\n",
              "1       6368402  ...  https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "2       6380781  ...  https://dq06ugkuram52.cloudfront.net/files/637...\n",
              "3       6364508  ...  https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "4       6379525  ...  https://dq06ugkuram52.cloudfront.net/files/635...\n",
              "...         ...  ...                                                ...\n",
              "1713    7311793  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1714    7310878  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1715    7310802  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1716    7311831  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "1717    7309810  ...  https://dq06ugkuram52.cloudfront.net/files/730...\n",
              "\n",
              "[1603 rows x 8 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf50c1ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5c1c65-33b5-4099-ad6a-1b96699373f0"
      },
      "source": [
        "stem_sentence_corpus = torch.load('drive/MyDrive/MSR_data/stem_sentence_corpus')\n",
        "\n",
        "stem_sentence_corpus_pd = pd.Series(stem_sentence_corpus)\n",
        "stem_sentence_corpus_pd"
      ],
      "id": "cf50c1ad",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [10/19/2020 slaveri and human trafﬁck | s.a., ...\n",
              "1       [modern slaveri act statement updated: septemb...\n",
              "2       [10/19/2020 slaveri | hall and woodhous modern...\n",
              "3       [green king | modern slaveri statement https:/...\n",
              "4       [charl well ltd modern slaveri and human traff...\n",
              "                              ...                        \n",
              "1713    [modern slaveri act 2015 statement our polici ...\n",
              "1714    [upto 60% off + 20% off end search for product...\n",
              "1715    [slaveri and human traffick transpar statement...\n",
              "1716    [reward gateway slaveri and human traffick sta...\n",
              "1717    [modern slaveri act statement – januari 2021 o...\n",
              "Length: 1718, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1azL9vU_TOhl",
        "outputId": "63afb72d-53a1-426c-c9fc-988c1778e53b"
      },
      "source": [
        "stem_sentence_corpus_pd.drop(short_list_1500)"
      ],
      "id": "1azL9vU_TOhl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       [10/19/2020 slaveri and human trafﬁck | s.a., ...\n",
              "1       [modern slaveri act statement updated: septemb...\n",
              "2       [10/19/2020 slaveri | hall and woodhous modern...\n",
              "3       [green king | modern slaveri statement https:/...\n",
              "4       [charl well ltd modern slaveri and human traff...\n",
              "                              ...                        \n",
              "1713    [modern slaveri act 2015 statement our polici ...\n",
              "1714    [upto 60% off + 20% off end search for product...\n",
              "1715    [slaveri and human traffick transpar statement...\n",
              "1716    [reward gateway slaveri and human traffick sta...\n",
              "1717    [modern slaveri act statement – januari 2021 o...\n",
              "Length: 1603, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37ed49be"
      },
      "source": [
        "data_tensor = torch.load('drive/MyDrive/MSR_data/data_tensor_fnl')\n",
        "data_tensor_np = data_tensor.detach().numpy()"
      ],
      "id": "37ed49be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo8DrG1URn8h",
        "outputId": "a1412271-eb00-421b-c82a-400b820af179"
      },
      "source": [
        "data_tensor_np1 = np.delete(data_tensor_np, short_list_1500, axis=0)\n",
        "data_tensor_np1.shape"
      ],
      "id": "uo8DrG1URn8h",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1603, 200, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-gNMDPYaVct",
        "outputId": "66096834-788c-46dd-f634-e7d415c392de"
      },
      "source": [
        "data_tensor2 = torch.tensor(data_tensor_np1)\n",
        "data_tensor2.size()"
      ],
      "id": "3-gNMDPYaVct",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1603, 200, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4d21773"
      },
      "source": [
        "#### I Tensor"
      ],
      "id": "b4d21773"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a9870c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "181a46e5-5413-47e2-ef67-3e6904be9eab"
      },
      "source": [
        "I_tensor1 = torch.load('drive/MyDrive/MSR_data/I_tensor')\n",
        "I_tensor1_np = I_tensor1.detach().numpy()\n",
        "I_tensor1_np1 = np.delete(I_tensor1_np, short_list_1500, axis=0)\n",
        "I_tensor1_np1.shape"
      ],
      "id": "2a9870c1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1603, 1, 200)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O62Bacf-Zwcm",
        "outputId": "97a585a2-e026-428c-b38a-86ca60624769"
      },
      "source": [
        "I_tensor2 = torch.tensor(I_tensor1_np1)\n",
        "I_tensor2.size()"
      ],
      "id": "O62Bacf-Zwcm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1603, 1, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50b22995"
      },
      "source": [
        "### Model training"
      ],
      "id": "50b22995"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbf0497f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66e56f30-5364-4907-c1cd-357b7f51ed6e"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "id": "fbf0497f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gfTDR1LcWyB",
        "outputId": "952b7cdf-b8ab-43dd-854b-91753ab813ca"
      },
      "source": [
        "label = df_csv_joined1['Value'].tolist()\n",
        "len(label)"
      ],
      "id": "1gfTDR1LcWyB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1603"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a98c0ee3"
      },
      "source": [
        "label = df_csv_joined1['Value'].tolist()\n",
        "\n",
        "train_x = data_tensor2[:1200]\n",
        "train_x = train_x.permute(0,2,1)\n",
        "train_y = torch.tensor(label[:1200])\n",
        "train_i = I_tensor2[:1200]\n",
        "\n",
        "val_x = data_tensor2[1200:]\n",
        "val_x = val_x.permute(0,2,1)\n",
        "val_y = torch.tensor(label[1200:])\n",
        "val_i = I_tensor2[1200:]\n",
        "\n",
        "test_x = data_tensor2[1200:]\n",
        "test_x = test_x.permute(0,2,1)\n",
        "test_y = torch.tensor(label[1200:])\n",
        "test_i = I_tensor2[1200:]"
      ],
      "id": "a98c0ee3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ea39972"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 50\n",
        "\n",
        "train_data = TensorDataset(train_x, train_y, train_i)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "val_data = TensorDataset(val_x, val_y, val_i)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size, shuffle=False)"
      ],
      "id": "7ea39972",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be4f5263"
      },
      "source": [
        "class model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        \n",
        "        super(model, self).__init__()\n",
        "                        \n",
        "        self.conv1 = nn.Conv1d(in_channels = 768, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "        \n",
        "        self.conv2 = nn.Conv1d(in_channels = 768, out_channels=1024, kernel_size=1, stride=1, padding=0)\n",
        "        \n",
        "        self.fc1 = nn.Linear(1024, 100)\n",
        "        \n",
        "        self.fc2 = nn.Linear(100, 2)\n",
        "                \n",
        "        self.softmax1 = nn.Softmax(dim=-1)\n",
        "        \n",
        "        self.softmax2 = nn.Softmax(dim=1)\n",
        "        \n",
        "        self.relu =  nn.ReLU()\n",
        "        \n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, x, y, i):\n",
        "        \n",
        "        lbda = 25\n",
        "                        \n",
        "        alpha = self.conv1(x) #(btch_sz, 768, 200)-> (btch_sz, 1, 200)\n",
        "        \n",
        "        x_2 = self.conv2(x)\n",
        "        \n",
        "        x_2 = self.relu(x_2)\n",
        "                                                        \n",
        "        alpha1 = alpha + lbda * i #(btch_sz, 1, 200) + (btch_sz,1, 200)*(btch_sz, 1, 200) \n",
        "                                \n",
        "        alpha_prime = self.softmax1(alpha1) #(btch_sz, 1, 200)\n",
        "                        \n",
        "        alpha_prime_permute = alpha_prime.permute(0,2,1) #(btch_sz, 200, 1) \n",
        "                                        \n",
        "        h = torch.matmul(x_2, alpha_prime_permute)  #(btch_sz, 768, 200)*(btch_sz, 200, 1) = (btch_sz, 768, 1)\n",
        "                                \n",
        "        h = h.view(h.shape[0], -1) #(btch_sz, 768)\n",
        "                        \n",
        "        output = self.relu(self.fc1(h)) #(btch_sz, 768, 512) \n",
        "        \n",
        "        output = self.dropout(output)\n",
        "        \n",
        "        output = self.fc2(output)\n",
        "        \n",
        "        output = self.softmax2(output)\n",
        "                                 \n",
        "        return output"
      ],
      "id": "be4f5263",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23296af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22854f13-2ebc-4e31-e729-c131fd55a402"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        " \n",
        "class_wts = compute_class_weight('balanced', classes= torch.unique(train_y).tolist(), y=train_y.tolist())\n",
        "\n",
        "print(class_wts)\n",
        "\n",
        "weights = torch.tensor(class_wts, dtype = torch.float)\n",
        "weights = weights.to(device)\n"
      ],
      "id": "23296af6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.05820106 0.9478673 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de667c96"
      },
      "source": [
        "from torch import optim\n",
        "\n",
        "Model = model()\n",
        "\n",
        "Model = Model.to(device)\n",
        "\n",
        "cross_entropy = nn.CrossEntropyLoss(weight=weights)\n",
        "\n",
        "from transformers import AdamW\n",
        "\n",
        "optimizer = optim.AdamW(Model.parameters(), lr = 0.001, weight_decay=1e-5)\n",
        "\n",
        "epochs = 100\n"
      ],
      "id": "de667c96",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f0f0d18"
      },
      "source": [
        "def train():\n",
        "    Model.train()\n",
        "    total_loss, total_accuracy = 0, 0\n",
        "\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        batch = [r.to(device) for r in batch]\n",
        " \n",
        "        x, y, i = batch\n",
        "\n",
        "        Model.zero_grad()        \n",
        "\n",
        "        preds = Model(x, y, i)\n",
        "\n",
        "        loss = cross_entropy(preds, y)\n",
        "\n",
        "        total_loss = total_loss + loss.item()\n",
        "     \n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(Model.parameters(), 1.0)  # clip the the gradients to 1.0, preventing the exploding gradient problem\n",
        "\n",
        "        optimizer.step()  # update parameters\n",
        "\n",
        "        _, predicted = torch.max(preds.data, 1)\n",
        "        train_total += y.size(0)\n",
        "        train_correct += (predicted == y).sum().item()\n",
        "\n",
        "        preds=preds.detach().cpu().numpy()   # if model predictions are stored on GPU, push it to CPU\n",
        "        \n",
        "    avg_loss = total_loss / len(train_dataloader) # compute the training loss of the epoch\n",
        "    train_acc = train_correct/train_total\n",
        "  \n",
        "    return avg_loss, train_acc #returns train loss and predictions\n"
      ],
      "id": "6f0f0d18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55179695"
      },
      "source": [
        "def evaluate():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "    Model.eval()   # deactivate dropout layers\n",
        "    total_loss = 0\n",
        "\n",
        "    val_total = 0\n",
        "    val_correct = 0\n",
        "\n",
        "    for step,batch in enumerate(val_dataloader):   # iterate over batches\n",
        "        \n",
        "        batch = [t.to(device) for t in batch] # push the batch to gpu\n",
        "\n",
        "        x, y, i = batch\n",
        "        \n",
        "        with torch.no_grad(): # deactivate autograd\n",
        "            \n",
        "            preds = Model(x, y, i)\n",
        "            \n",
        "            loss = cross_entropy(preds,y)\n",
        "\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            _, predicted = torch.max(preds.data, 1)\n",
        "            val_total += y.size(0)\n",
        "            val_correct += (predicted == y).sum().item()\n",
        "\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            \n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "    val_acc = val_correct/val_total\n",
        "\n",
        "    return avg_loss, val_acc"
      ],
      "id": "55179695",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f71e6bdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e5e66d-7538-49cb-fcfa-25773500b3ee"
      },
      "source": [
        "import numpy as np\n",
        "best_valid_loss = float('inf')  # set initial loss to infinite\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "train_acces = []\n",
        "val_acces = []\n",
        "\n",
        "for epoch in range(epochs): #for each epoch\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    train_loss, train_acc = train() #train model\n",
        "    valid_loss, val_acc = evaluate() #evaluate model\n",
        "    \n",
        "    if valid_loss < best_valid_loss: #save the best model\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(Model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    \n",
        "    train_acces.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    val_acces.append(val_acces)\n",
        "    \n",
        "    print('Train acc', np.round(train_acc, 3), 'Val acc', np.round(val_acc, 3))\n",
        "    print('Train loss', np.round(train_loss, 3), 'Val loss', np.round(valid_loss, 3))\n"
      ],
      "id": "f71e6bdb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.652 Val acc 0.68\n",
            "Train loss 0.671 Val loss 0.647\n",
            "\n",
            " Epoch 2 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.665 Val acc 0.68\n",
            "Train loss 0.644 Val loss 0.65\n",
            "\n",
            " Epoch 3 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.668 Val acc 0.521\n",
            "Train loss 0.631 Val loss 0.683\n",
            "\n",
            " Epoch 4 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.664 Val acc 0.64\n",
            "Train loss 0.626 Val loss 0.661\n",
            "\n",
            " Epoch 5 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.668 Val acc 0.68\n",
            "Train loss 0.623 Val loss 0.638\n",
            "\n",
            " Epoch 6 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.686 Val acc 0.663\n",
            "Train loss 0.616 Val loss 0.642\n",
            "\n",
            " Epoch 7 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.635\n",
            "Train loss 0.617 Val loss 0.651\n",
            "\n",
            " Epoch 8 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.654 Val acc 0.672\n",
            "Train loss 0.618 Val loss 0.637\n",
            "\n",
            " Epoch 9 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.676 Val acc 0.675\n",
            "Train loss 0.62 Val loss 0.64\n",
            "\n",
            " Epoch 10 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.672 Val acc 0.558\n",
            "Train loss 0.615 Val loss 0.68\n",
            "\n",
            " Epoch 11 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.682 Val acc 0.603\n",
            "Train loss 0.614 Val loss 0.658\n",
            "\n",
            " Epoch 12 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.687 Val acc 0.655\n",
            "Train loss 0.614 Val loss 0.642\n",
            "\n",
            " Epoch 13 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.678 Val acc 0.663\n",
            "Train loss 0.615 Val loss 0.641\n",
            "\n",
            " Epoch 14 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.691 Val acc 0.638\n",
            "Train loss 0.613 Val loss 0.651\n",
            "\n",
            " Epoch 15 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.686 Val acc 0.658\n",
            "Train loss 0.611 Val loss 0.643\n",
            "\n",
            " Epoch 16 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.69 Val acc 0.643\n",
            "Train loss 0.61 Val loss 0.644\n",
            "\n",
            " Epoch 17 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.684 Val acc 0.638\n",
            "Train loss 0.611 Val loss 0.647\n",
            "\n",
            " Epoch 18 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.686 Val acc 0.663\n",
            "Train loss 0.615 Val loss 0.64\n",
            "\n",
            " Epoch 19 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.686 Val acc 0.655\n",
            "Train loss 0.611 Val loss 0.644\n",
            "\n",
            " Epoch 20 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.675\n",
            "Train loss 0.61 Val loss 0.638\n",
            "\n",
            " Epoch 21 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.618\n",
            "Train loss 0.611 Val loss 0.662\n",
            "\n",
            " Epoch 22 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.689 Val acc 0.665\n",
            "Train loss 0.612 Val loss 0.64\n",
            "\n",
            " Epoch 23 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.683 Val acc 0.672\n",
            "Train loss 0.612 Val loss 0.639\n",
            "\n",
            " Epoch 24 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.679 Val acc 0.68\n",
            "Train loss 0.618 Val loss 0.641\n",
            "\n",
            " Epoch 25 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.68\n",
            "Train loss 0.615 Val loss 0.637\n",
            "\n",
            " Epoch 26 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.623\n",
            "Train loss 0.617 Val loss 0.677\n",
            "\n",
            " Epoch 27 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.689 Val acc 0.68\n",
            "Train loss 0.616 Val loss 0.639\n",
            "\n",
            " Epoch 28 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.691 Val acc 0.66\n",
            "Train loss 0.612 Val loss 0.642\n",
            "\n",
            " Epoch 29 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.62\n",
            "Train loss 0.61 Val loss 0.699\n",
            "\n",
            " Epoch 30 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.679 Val acc 0.672\n",
            "Train loss 0.62 Val loss 0.64\n",
            "\n",
            " Epoch 31 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.677\n",
            "Train loss 0.608 Val loss 0.636\n",
            "\n",
            " Epoch 32 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.677\n",
            "Train loss 0.609 Val loss 0.638\n",
            "\n",
            " Epoch 33 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.682\n",
            "Train loss 0.607 Val loss 0.635\n",
            "\n",
            " Epoch 34 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.66\n",
            "Train loss 0.608 Val loss 0.646\n",
            "\n",
            " Epoch 35 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.672\n",
            "Train loss 0.607 Val loss 0.638\n",
            "\n",
            " Epoch 36 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.691 Val acc 0.675\n",
            "Train loss 0.605 Val loss 0.637\n",
            "\n",
            " Epoch 37 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.691 Val acc 0.685\n",
            "Train loss 0.607 Val loss 0.635\n",
            "\n",
            " Epoch 38 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.691 Val acc 0.64\n",
            "Train loss 0.605 Val loss 0.647\n",
            "\n",
            " Epoch 39 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.699 Val acc 0.682\n",
            "Train loss 0.602 Val loss 0.636\n",
            "\n",
            " Epoch 40 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.663\n",
            "Train loss 0.612 Val loss 0.639\n",
            "\n",
            " Epoch 41 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.696 Val acc 0.677\n",
            "Train loss 0.604 Val loss 0.635\n",
            "\n",
            " Epoch 42 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.684 Val acc 0.623\n",
            "Train loss 0.61 Val loss 0.657\n",
            "\n",
            " Epoch 43 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.672\n",
            "Train loss 0.607 Val loss 0.636\n",
            "\n",
            " Epoch 44 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.667\n",
            "Train loss 0.603 Val loss 0.637\n",
            "\n",
            " Epoch 45 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.677\n",
            "Train loss 0.606 Val loss 0.635\n",
            "\n",
            " Epoch 46 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.65\n",
            "Train loss 0.604 Val loss 0.642\n",
            "\n",
            " Epoch 47 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.695 Val acc 0.665\n",
            "Train loss 0.605 Val loss 0.639\n",
            "\n",
            " Epoch 48 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.663\n",
            "Train loss 0.606 Val loss 0.639\n",
            "\n",
            " Epoch 49 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.665\n",
            "Train loss 0.606 Val loss 0.638\n",
            "\n",
            " Epoch 50 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.645\n",
            "Train loss 0.604 Val loss 0.64\n",
            "\n",
            " Epoch 51 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.665\n",
            "Train loss 0.604 Val loss 0.637\n",
            "\n",
            " Epoch 52 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.665\n",
            "Train loss 0.605 Val loss 0.637\n",
            "\n",
            " Epoch 53 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.683 Val acc 0.633\n",
            "Train loss 0.606 Val loss 0.643\n",
            "\n",
            " Epoch 54 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.66\n",
            "Train loss 0.607 Val loss 0.639\n",
            "\n",
            " Epoch 55 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.67\n",
            "Train loss 0.606 Val loss 0.637\n",
            "\n",
            " Epoch 56 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.667\n",
            "Train loss 0.605 Val loss 0.638\n",
            "\n",
            " Epoch 57 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.69 Val acc 0.638\n",
            "Train loss 0.605 Val loss 0.643\n",
            "\n",
            " Epoch 58 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.699 Val acc 0.677\n",
            "Train loss 0.608 Val loss 0.635\n",
            "\n",
            " Epoch 59 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.635\n",
            "Train loss 0.605 Val loss 0.651\n",
            "\n",
            " Epoch 60 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.695 Val acc 0.67\n",
            "Train loss 0.606 Val loss 0.636\n",
            "\n",
            " Epoch 61 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.635\n",
            "Train loss 0.603 Val loss 0.642\n",
            "\n",
            " Epoch 62 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.699 Val acc 0.665\n",
            "Train loss 0.604 Val loss 0.638\n",
            "\n",
            " Epoch 63 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.65\n",
            "Train loss 0.602 Val loss 0.641\n",
            "\n",
            " Epoch 64 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.64\n",
            "Train loss 0.607 Val loss 0.649\n",
            "\n",
            " Epoch 65 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.678 Val acc 0.66\n",
            "Train loss 0.606 Val loss 0.641\n",
            "\n",
            " Epoch 66 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.686 Val acc 0.643\n",
            "Train loss 0.606 Val loss 0.647\n",
            "\n",
            " Epoch 67 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.689 Val acc 0.672\n",
            "Train loss 0.607 Val loss 0.637\n",
            "\n",
            " Epoch 68 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.69 Val acc 0.667\n",
            "Train loss 0.606 Val loss 0.643\n",
            "\n",
            " Epoch 69 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.69 Val acc 0.675\n",
            "Train loss 0.605 Val loss 0.634\n",
            "\n",
            " Epoch 70 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.67\n",
            "Train loss 0.603 Val loss 0.639\n",
            "\n",
            " Epoch 71 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.667\n",
            "Train loss 0.605 Val loss 0.637\n",
            "\n",
            " Epoch 72 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.667\n",
            "Train loss 0.606 Val loss 0.637\n",
            "\n",
            " Epoch 73 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.695 Val acc 0.672\n",
            "Train loss 0.606 Val loss 0.633\n",
            "\n",
            " Epoch 74 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.695 Val acc 0.635\n",
            "Train loss 0.602 Val loss 0.641\n",
            "\n",
            " Epoch 75 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.695 Val acc 0.638\n",
            "Train loss 0.607 Val loss 0.643\n",
            "\n",
            " Epoch 76 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.689 Val acc 0.665\n",
            "Train loss 0.607 Val loss 0.641\n",
            "\n",
            " Epoch 77 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.67\n",
            "Train loss 0.603 Val loss 0.637\n",
            "\n",
            " Epoch 78 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.689 Val acc 0.638\n",
            "Train loss 0.603 Val loss 0.645\n",
            "\n",
            " Epoch 79 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.691 Val acc 0.665\n",
            "Train loss 0.605 Val loss 0.636\n",
            "\n",
            " Epoch 80 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.655\n",
            "Train loss 0.604 Val loss 0.641\n",
            "\n",
            " Epoch 81 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.697 Val acc 0.67\n",
            "Train loss 0.604 Val loss 0.636\n",
            "\n",
            " Epoch 82 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.638\n",
            "Train loss 0.607 Val loss 0.648\n",
            "\n",
            " Epoch 83 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.677\n",
            "Train loss 0.615 Val loss 0.634\n",
            "\n",
            " Epoch 84 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.667\n",
            "Train loss 0.605 Val loss 0.637\n",
            "\n",
            " Epoch 85 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.697 Val acc 0.66\n",
            "Train loss 0.603 Val loss 0.639\n",
            "\n",
            " Epoch 86 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.67\n",
            "Train loss 0.606 Val loss 0.636\n",
            "\n",
            " Epoch 87 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.658\n",
            "Train loss 0.601 Val loss 0.64\n",
            "\n",
            " Epoch 88 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.67\n",
            "Train loss 0.603 Val loss 0.637\n",
            "\n",
            " Epoch 89 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.682\n",
            "Train loss 0.604 Val loss 0.633\n",
            "\n",
            " Epoch 90 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.686 Val acc 0.667\n",
            "Train loss 0.608 Val loss 0.635\n",
            "\n",
            " Epoch 91 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.695 Val acc 0.67\n",
            "Train loss 0.603 Val loss 0.639\n",
            "\n",
            " Epoch 92 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.678 Val acc 0.633\n",
            "Train loss 0.608 Val loss 0.643\n",
            "\n",
            " Epoch 93 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.683 Val acc 0.67\n",
            "Train loss 0.607 Val loss 0.638\n",
            "\n",
            " Epoch 94 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.696 Val acc 0.667\n",
            "Train loss 0.603 Val loss 0.639\n",
            "\n",
            " Epoch 95 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.697 Val acc 0.655\n",
            "Train loss 0.603 Val loss 0.641\n",
            "\n",
            " Epoch 96 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.699 Val acc 0.64\n",
            "Train loss 0.601 Val loss 0.642\n",
            "\n",
            " Epoch 97 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.701 Val acc 0.667\n",
            "Train loss 0.601 Val loss 0.637\n",
            "\n",
            " Epoch 98 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.67\n",
            "Train loss 0.603 Val loss 0.639\n",
            "\n",
            " Epoch 99 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.689 Val acc 0.653\n",
            "Train loss 0.604 Val loss 0.641\n",
            "\n",
            " Epoch 100 / 100\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.688 Val acc 0.665\n",
            "Train loss 0.604 Val loss 0.636\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNS0HjWAKMc1",
        "outputId": "8844eb1b-5ba4-4fbd-f204-6ae4e203825f"
      },
      "source": [
        "path = 'saved_weights.pt'\n",
        "Model.load_state_dict(torch.load(path))\n",
        "\n",
        "print('Train_report:')\n",
        "with torch.no_grad():\n",
        "  train_preds = Model(train_x.to(device), train_y.to(device), train_i.to(device))\n",
        "  train_preds = train_preds.detach().cpu().numpy()\n",
        "\n",
        "train_preds = np.argmax(train_preds, axis = 1)\n",
        "print(classification_report(train_y, train_preds))\n",
        "\n",
        "\n",
        "print('Val_report:')\n",
        "with torch.no_grad():\n",
        "  val_preds = Model(val_x.to(device), val_y.to(device), val_i.to(device))\n",
        "  val_preds = val_preds.detach().cpu().numpy()\n",
        "\n",
        "val_preds = np.argmax(val_preds, axis = 1)\n",
        "print(classification_report(val_y, val_preds))\n",
        "\n",
        "print('Test_report:')\n",
        "with torch.no_grad():\n",
        "  test_preds = Model(test_x.to(device), test_y.to(device), test_i.to(device))\n",
        "  test_preds = test_preds.detach().cpu().numpy()\n",
        "\n",
        "test_preds = np.argmax(test_preds, axis = 1)\n",
        "print(classification_report(test_y, test_preds))"
      ],
      "id": "rNS0HjWAKMc1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.49      0.60       567\n",
            "           1       0.66      0.87      0.75       633\n",
            "\n",
            "    accuracy                           0.69      1200\n",
            "   macro avg       0.71      0.68      0.68      1200\n",
            "weighted avg       0.71      0.69      0.68      1200\n",
            "\n",
            "Val_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.31      0.42       150\n",
            "           1       0.69      0.91      0.78       253\n",
            "\n",
            "    accuracy                           0.68       403\n",
            "   macro avg       0.67      0.61      0.60       403\n",
            "weighted avg       0.68      0.68      0.65       403\n",
            "\n",
            "Test_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.66      0.31      0.42       150\n",
            "           1       0.69      0.91      0.78       253\n",
            "\n",
            "    accuracy                           0.68       403\n",
            "   macro avg       0.67      0.61      0.60       403\n",
            "weighted avg       0.68      0.68      0.65       403\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgaBZLHfjpyk"
      },
      "source": [
        "x = list(range(0,100))\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.plot(x, train_acces)\n",
        "plt.plot(x, val_acces)\n",
        "\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model train and validation loss')"
      ],
      "id": "jgaBZLHfjpyk",
      "execution_count": null,
      "outputs": []
    }
  ]
}