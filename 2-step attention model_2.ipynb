{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "20210911a_0920_2stages_alpha2_0.74.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fe7bfb5",
        "outputId": "02a3e566-ce98-4fda-b7c6-2078749ac7d6"
      },
      "source": [
        "pip install transformers"
      ],
      "id": "3fe7bfb5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.10.3-py3-none-any.whl (2.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8 MB 13.3 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 77.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 73.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 83.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting huggingface-hub>=0.0.12\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.12->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.10.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygQU-FEZf052"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer, BertForSequenceClassification"
      ],
      "id": "ygQU-FEZf052",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fukxbRIQf98i",
        "outputId": "c2ad8568-0cf5-4f62-8ad9-108367b6aa7d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "fukxbRIQf98i",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "5d418a32",
        "outputId": "2925679e-505a-4829-ab2d-cd8c3c68eab0"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('drive/MyDrive/MSR_data_0910/0906.csv')\n",
        "df"
      ],
      "id": "5d418a32",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Value</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10/19/2020\\nSLAVERY AND HUMAN TRAFFICKING\\nINT...</td>\n",
              "      <td>Whistleblower protection (direct employees), W...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Pension\\nProtection\\nFund\\nPension\\nProtection...</td>\n",
              "      <td>Whistleblower protection (direct employees), I...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10/19/2020\\nModern Slavery &amp; Human\\nTroffickin...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Greene King I MODERN SLAVERY STATEMENT\\nMODERN...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Charles Wells Ltd\\nModern Slavery and Human Tr...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>1376</td>\n",
              "      <td>Modern Slavery Act 2015 Statement\\nOur Policy\\...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>1377</td>\n",
              "      <td>Upto 60% off + 20% off ends\\n\\nSearch for\\npro...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1378</th>\n",
              "      <td>1378</td>\n",
              "      <td>Slavery and Human Trafficking Transparency Sta...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1379</th>\n",
              "      <td>1379</td>\n",
              "      <td>Reward Gateway Slavery\\nand Human Trafficking\\...</td>\n",
              "      <td>Hotline (direct employees), Whistleblower prot...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380</th>\n",
              "      <td>1380</td>\n",
              "      <td>Modern Slavery Act Statement\\n– January 2021\\n...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1381 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... label\n",
              "0              0  ...     1\n",
              "1              1  ...     0\n",
              "2              2  ...     1\n",
              "3              3  ...     1\n",
              "4              4  ...     1\n",
              "...          ...  ...   ...\n",
              "1376        1376  ...     0\n",
              "1377        1377  ...     0\n",
              "1378        1378  ...     1\n",
              "1379        1379  ...     1\n",
              "1380        1380  ...     0\n",
              "\n",
              "[1381 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJLS3wgyhPLx",
        "outputId": "d160c9a3-8ea0-4b2d-d0ec-9adf39f86ab0"
      },
      "source": [
        "df.label.value_counts()"
      ],
      "id": "yJLS3wgyhPLx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    735\n",
              "0    646\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KrtuJk2WyC_",
        "outputId": "fff7840e-ed6c-4a29-99ba-f285893fa2ab"
      },
      "source": [
        "print(df['label'][:450].value_counts())\n",
        "print(df['label'][450:].value_counts())"
      ],
      "id": "1KrtuJk2WyC_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    234\n",
            "0    216\n",
            "Name: label, dtype: int64\n",
            "1    501\n",
            "0    430\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37ed49be",
        "outputId": "6717a4ec-71a6-4005-c7f7-b8dd19d6254f"
      },
      "source": [
        "data_tensor = torch.load('drive/MyDrive/MSR_data_0910/data_tensor_0910')\n",
        "\n",
        "print(data_tensor.size())"
      ],
      "id": "37ed49be",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1381, 200, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cw6MdSOuT_vJ",
        "outputId": "2dcb1d10-8f99-406f-82f2-3fb15d6cb2ab"
      },
      "source": [
        "aug_tensor = torch.load('drive/MyDrive/MSR_data_0910/aug_tensor_0922')\n",
        "print(aug_tensor.size())\n",
        "\n",
        "aug_label = torch.load('drive/MyDrive/MSR_data_0910/aug_label')\n",
        "print(aug_label.size())\n",
        "\n",
        "I_tensor_aug = torch.load('drive/MyDrive/MSR_data_0910/I_tensor_aug')\n",
        "print(I_tensor_aug.size())"
      ],
      "id": "Cw6MdSOuT_vJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([254, 200, 768])\n",
            "torch.Size([254])\n",
            "torch.Size([254, 1, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4d21773"
      },
      "source": [
        "#### I Tensor"
      ],
      "id": "b4d21773"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2a9870c1",
        "outputId": "54fb5c03-ed3c-4575-cb66-aafe3a320019"
      },
      "source": [
        "I_tensor = torch.load('drive/MyDrive/MSR_data_0910/I_tensor0922')\n",
        "\n",
        "print(I_tensor.size())\n"
      ],
      "id": "2a9870c1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1381, 1, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50b22995"
      },
      "source": [
        "### Model training"
      ],
      "id": "50b22995"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbf0497f",
        "outputId": "176d3e79-06cb-40e8-d2a7-810a09fb9517"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "id": "fbf0497f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gfTDR1LcWyB",
        "outputId": "a29da7a4-56e4-4a88-d0b9-d62f5ab8e86f"
      },
      "source": [
        "label = df['label'].tolist()\n",
        "len(label)"
      ],
      "id": "1gfTDR1LcWyB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1381"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a98c0ee3",
        "outputId": "6eed8afd-1aec-48f3-937c-dd1af62cfc00"
      },
      "source": [
        "label = df['label'].tolist()\n",
        "\n",
        "train_x = data_tensor[:1000]\n",
        "#train_x = torch.cat((train_x, aug_tensor[150:]), 0)\n",
        "print(train_x.shape)\n",
        "train_x = train_x.permute(0,2,1)\n",
        "\n",
        "\n",
        "train_y = torch.tensor(label[:1000])\n",
        "#train_y = torch.cat((train_y, aug_label[150:]), 0)\n",
        "print(train_y.shape)\n",
        "\n",
        "train_i = I_tensor[:1000]\n",
        "#train_i = torch.cat((train_i, I_tensor_aug[150:]), 0)\n",
        "print(train_i.shape)\n",
        "\n",
        "val_x = data_tensor[1000:]\n",
        "val_x = val_x.permute(0,2,1)\n",
        "val_y = torch.tensor(label[1000:])\n",
        "val_i = I_tensor[1000:]\n",
        "\n",
        "test_x = data_tensor[1000:]\n",
        "test_x = test_x.permute(0,2,1)\n",
        "test_y = torch.tensor(label[1000:])\n",
        "test_i = I_tensor[1000:]\n"
      ],
      "id": "a98c0ee3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1000, 200, 768])\n",
            "torch.Size([1000])\n",
            "torch.Size([1000, 1, 200])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ea39972"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_data = TensorDataset(train_x, train_y, train_i)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler = train_sampler, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "val_data = TensorDataset(val_x, val_y, val_i)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size, shuffle=False)"
      ],
      "id": "7ea39972",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be4f5263"
      },
      "source": [
        "#Stage_1\n",
        "\n",
        "class model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model, self).__init__()        \n",
        "        self.conv1 = nn.Conv1d(in_channels = 768, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv2 = nn.Conv1d(in_channels = 768, out_channels=100, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.fc1 = nn.Linear(100, 100)\n",
        "        self.fc2 = nn.Linear(100, 2)  \n",
        "\n",
        "        self.softmax1 = nn.Softmax(dim=-1)\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        self.conv1_bn = nn.BatchNorm1d(1)\n",
        "        self.conv2_bn = nn.BatchNorm1d(100)\n",
        "        self.dense1_bn = nn.BatchNorm1d(100)\n",
        "      \n",
        "    def forward(self, x, y, i):        \n",
        "        \n",
        "        alpha = self.conv1_bn(self.conv1(x)) #(btch_sz, 768, 200)*(btch_sz, 768, 1) -> (btch_sz, 1, 200)   \n",
        "\n",
        "        alpha_prime = self.softmax1(alpha) #(btch_sz, 1, 200)   \n",
        "        alpha_prime_permute = alpha_prime.permute(0,2,1) #(btch_sz, 200, 1)     \n",
        "\n",
        "        x_2 = self.relu(self.conv2_bn(self.conv2(x)))                        \n",
        "        h = torch.matmul(x_2, alpha_prime_permute)  #(btch_sz, 768, 200)*(btch_sz, 200, 1) = (btch_sz, 768, 1)         \n",
        "        h = h.view(h.shape[0], -1) #(btch_sz, 768)             \n",
        "        \n",
        "        output = self.relu(self.dense1_bn(self.fc1(h))) #(btch_sz, 768, 512) \n",
        "        output = self.fc2(output)  \n",
        "\n",
        "        alpha_prime1 = alpha_prime.view(alpha_prime.shape[0], -1)           \n",
        "        return alpha_prime1, output\n"
      ],
      "id": "be4f5263",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f0f0d18"
      },
      "source": [
        "def train():\n",
        "    Model.train()\n",
        "    total_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        x, y, i = batch\n",
        "        Model.zero_grad()        \n",
        "        \n",
        "        alpha_pred, output_preds = Model(x, y, i)\n",
        "\n",
        "        i = i.view(i.shape[0], -1)\n",
        "        softmax1 = nn.Softmax(dim=-1)\n",
        "        i = softmax1(i)\n",
        "\n",
        "        loss = beta*(MSEloss(alpha_pred, i)) + cross_entropy(output_preds, y)\n",
        "        total_loss = total_loss + loss.item()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        _, predicted = torch.max(output_preds.data, 1)\n",
        "        train_total += y.size(0)\n",
        "        train_correct += (predicted == y).sum().item()\n",
        "        output_preds = output_preds.detach().cpu().numpy()   \n",
        "        \n",
        "    avg_loss = total_loss / len(train_dataloader) \n",
        "    train_acc = train_correct/train_total\n",
        "  \n",
        "    return avg_loss, train_acc \n"
      ],
      "id": "6f0f0d18",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55179695"
      },
      "source": [
        "def evaluate():\n",
        "    \n",
        "    print(\"\\nEvaluating...\")\n",
        "    Model.eval()   # deactivate dropout layers\n",
        "    total_loss = 0\n",
        "    val_total = 0\n",
        "    val_correct = 0\n",
        "\n",
        "    for step,batch in enumerate(val_dataloader):   # iterate over batches\n",
        "        batch = [t.to(device) for t in batch] # push the batch to gpu\n",
        "        x, y, i = batch\n",
        "        \n",
        "        with torch.no_grad(): # deactivate autograd \n",
        "            alpha_pred, output_preds = Model(x, y, i)\n",
        "\n",
        "            i = i.view(i.shape[0], -1)\n",
        "            softmax1 = nn.Softmax(dim=-1)\n",
        "            i = softmax1(i)\n",
        "\n",
        "            loss = beta*(MSEloss(alpha_pred, i)) + cross_entropy(output_preds, y)\n",
        "            total_loss = total_loss + loss.item()\n",
        "\n",
        "            _, predicted = torch.max(output_preds.data, 1)\n",
        "            val_total += y.size(0)\n",
        "            val_correct += (predicted == y).sum().item()\n",
        "            output_preds = output_preds.detach().cpu().numpy()\n",
        "            \n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "    val_acc = val_correct/val_total\n",
        "\n",
        "    return avg_loss, val_acc"
      ],
      "id": "55179695",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PWCwNOz6O25",
        "outputId": "b664988e-0890-40e4-9023-3b18c906f6d3"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        " \n",
        "class_wts = compute_class_weight('balanced', classes= torch.unique(train_y).tolist(), y=train_y.tolist())\n",
        "print(class_wts)\n",
        "weights = torch.tensor(class_wts, dtype = torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "from torch import optim\n",
        "Model = model()\n",
        "Model = Model.to(device)\n",
        "cross_entropy = nn.CrossEntropyLoss(weight=weights)\n",
        "MSEloss = nn.MSELoss()\n",
        "\n",
        "from transformers import AdamW\n",
        "optimizer = optim.AdamW(Model.parameters(), lr = 0.0005, weight_decay=0.01)\n",
        "epochs = 5"
      ],
      "id": "4PWCwNOz6O25",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.01010101 0.99009901]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f71e6bdb",
        "outputId": "9e541be7-a56b-4c36-dc33-d6da743ab850"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "best_valid_loss = float('inf')  \n",
        "\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "train_acces = []\n",
        "val_acces = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "  if epoch <=5:\n",
        "    beta = 1\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    train_loss, train_acc = train() \n",
        "    valid_loss, val_acc = evaluate() \n",
        "\n",
        "    if valid_loss < best_valid_loss: \n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(Model.state_dict(), '/content/drive/MyDrive/MSR_data_0910/stage1_alpha_weights.pt')\n",
        "    \n",
        "    train_acces.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    val_acces.append(val_acces)\n",
        "    \n",
        "    print('Train acc', np.round(train_acc, 3), 'Val acc', np.round(val_acc, 3))\n",
        "    print('Train loss', np.round(train_loss, 3), 'Val loss', np.round(valid_loss, 3))\n",
        "\n",
        "  else:\n",
        "    beta = 0\n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    train_loss, train_acc = train() \n",
        "    valid_loss, val_acc = evaluate() \n",
        "\n",
        "    if valid_loss < best_valid_loss: \n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(Model.state_dict(), '/content/drive/MyDrive/MSR_data_0910/0920_stage1_alpha_weights.pt')\n",
        "    \n",
        "    train_acces.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    val_acces.append(val_acces)\n",
        "    \n",
        "    print('Train acc', np.round(train_acc, 3), 'Val acc', np.round(val_acc, 3))\n",
        "    print('Train loss', np.round(train_loss, 3), 'Val loss', np.round(valid_loss, 3))\n",
        "\n"
      ],
      "id": "f71e6bdb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 5\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.659 Val acc 0.669\n",
            "Train loss 0.634 Val loss 0.611\n",
            "\n",
            " Epoch 2 / 5\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.67 Val acc 0.706\n",
            "Train loss 0.627 Val loss 0.6\n",
            "\n",
            " Epoch 3 / 5\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.665 Val acc 0.706\n",
            "Train loss 0.637 Val loss 0.599\n",
            "\n",
            " Epoch 4 / 5\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.676 Val acc 0.706\n",
            "Train loss 0.631 Val loss 0.598\n",
            "\n",
            " Epoch 5 / 5\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.654 Val acc 0.706\n",
            "Train loss 0.633 Val loss 0.598\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-aigKBGKbZt",
        "outputId": "250a36b2-d749-4dac-b407-23b8b7423a0c"
      },
      "source": [
        "path = '/content/drive/MyDrive/MSR_data_0910/0920_2stages_0.74_acc_weights/0920_stage1_alpha_weights.pt'\n",
        "Model.load_state_dict(torch.load(path))\n",
        "\n",
        "for param_tensor in Model.state_dict():\n",
        "    print(param_tensor, \"\\t\", Model.state_dict()[param_tensor].size())\n",
        "\n"
      ],
      "id": "o-aigKBGKbZt",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "conv1.weight \t torch.Size([1, 768, 1])\n",
            "conv1.bias \t torch.Size([1])\n",
            "conv2.weight \t torch.Size([100, 768, 1])\n",
            "conv2.bias \t torch.Size([100])\n",
            "fc1.weight \t torch.Size([100, 100])\n",
            "fc1.bias \t torch.Size([100])\n",
            "fc2.weight \t torch.Size([2, 100])\n",
            "fc2.bias \t torch.Size([2])\n",
            "conv1_bn.weight \t torch.Size([1])\n",
            "conv1_bn.bias \t torch.Size([1])\n",
            "conv1_bn.running_mean \t torch.Size([1])\n",
            "conv1_bn.running_var \t torch.Size([1])\n",
            "conv1_bn.num_batches_tracked \t torch.Size([])\n",
            "conv2_bn.weight \t torch.Size([100])\n",
            "conv2_bn.bias \t torch.Size([100])\n",
            "conv2_bn.running_mean \t torch.Size([100])\n",
            "conv2_bn.running_var \t torch.Size([100])\n",
            "conv2_bn.num_batches_tracked \t torch.Size([])\n",
            "dense1_bn.weight \t torch.Size([100])\n",
            "dense1_bn.bias \t torch.Size([100])\n",
            "dense1_bn.running_mean \t torch.Size([100])\n",
            "dense1_bn.running_var \t torch.Size([100])\n",
            "dense1_bn.num_batches_tracked \t torch.Size([])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJ68j8tLRBR"
      },
      "source": [
        "#Stage_2\n",
        "\n",
        "class model_2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(model_2, self).__init__()        \n",
        "        self.conv1 = nn.Conv1d(in_channels = 768, out_channels=1, kernel_size=1, stride=1, padding=0)\n",
        "        self.conv1.weight = nn.Parameter(Model.state_dict()['conv1.weight'], requires_grad = True)\n",
        "        self.conv2 = nn.Conv1d(in_channels = 768, out_channels=100, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        self.fc1 = nn.Linear(100, 100)\n",
        "        self.fc2 = nn.Linear(100, 2)  \n",
        "\n",
        "        self.softmax1 = nn.Softmax(dim=-1)\n",
        "        self.relu =  nn.ReLU()\n",
        "\n",
        "        self.conv1_bn = nn.BatchNorm1d(1)\n",
        "        self.conv2_bn = nn.BatchNorm1d(100)\n",
        "        self.dense1_bn = nn.BatchNorm1d(100)\n",
        "\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "        \n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, x, y, i):\n",
        "        lbda = 5      \n",
        "        alpha = self.conv1_bn(self.conv1(x)) #(btch_sz, 768, 200)-> (btch_sz, 1, 200)                                   \n",
        "        alpha1 = alpha + lbda * i #(btch_sz, 1, 200) + (btch_sz,1, 200)*(btch_sz, 1, 200)                    \n",
        "        alpha_prime = self.softmax1(alpha1) #(btch_sz, 1, 200)          \n",
        "        alpha_prime_permute = alpha_prime.permute(0,2,1) #(btch_sz, 200, 1)     \n",
        "\n",
        "        x_2 = self.relu(self.conv2_bn(self.conv2(x)))                        \n",
        "        \n",
        "        h = torch.matmul(x_2, alpha_prime_permute)  #(btch_sz, 768, 200)*(btch_sz, 200, 1) = (btch_sz, 768, 1)         \n",
        "        h = h.view(h.shape[0], -1) #(btch_sz, 768)             \n",
        "        \n",
        "        output = self.relu(self.dense1_bn (self.fc1(h))) #(btch_sz, 768, 512) \n",
        "        output = self.dropout(output)\n",
        "        output = self.fc2(output)             \n",
        "        return output"
      ],
      "id": "aoJ68j8tLRBR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcUUz_PbLRG_",
        "outputId": "7fb5bb15-2e5b-4ae9-8acc-1c026992b002"
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        " \n",
        "class_wts = compute_class_weight('balanced', classes= torch.unique(train_y).tolist(), y=train_y.tolist())\n",
        "print(class_wts)\n",
        "weights = torch.tensor(class_wts, dtype = torch.float)\n",
        "weights = weights.to(device)\n",
        "cross_entropy = nn.CrossEntropyLoss(weight=weights)\n"
      ],
      "id": "wcUUz_PbLRG_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.01010101 0.99009901]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCUs2ooxLRJm"
      },
      "source": [
        "path = '/content/drive/MyDrive/MSR_data_0910/0920_2stages_0.74_acc_weights/0920_stage1_alpha_weights.pt'\n",
        "\n",
        "Model_2 = model_2()\n",
        "Model_2.load_state_dict(torch.load(path))\n",
        "Model_2 = Model_2.to(device)\n",
        "\n",
        "from torch import optim\n",
        "from transformers import AdamW\n",
        "optimizer = optim.AdamW(Model_2.parameters(), lr = 0.0005, weight_decay=0.01)\n",
        "epochs = 75\n"
      ],
      "id": "BCUs2ooxLRJm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYZbGZ1yLRMd"
      },
      "source": [
        "def train():\n",
        "    Model_2.train()\n",
        "    total_loss = 0\n",
        "    train_correct = 0\n",
        "    train_total = 0\n",
        "    \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        batch = [r.to(device) for r in batch]\n",
        "        x, y, i = batch\n",
        "        Model_2.zero_grad()        \n",
        "        \n",
        "        preds = Model_2(x, y, i)\n",
        "        loss = cross_entropy(preds, y)\n",
        "        total_loss = total_loss + loss.item()\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()  # update parameters\n",
        "        \n",
        "        _, predicted = torch.max(preds.data, 1)\n",
        "        train_total += y.size(0)\n",
        "        train_correct += (predicted == y).sum().item()\n",
        "        preds=preds.detach().cpu().numpy()   # if model predictions are stored on GPU, push it to CPU\n",
        "        \n",
        "    avg_loss = total_loss / len(train_dataloader) # compute the training loss of the epoch\n",
        "    train_acc = train_correct/train_total\n",
        "  \n",
        "    return avg_loss, train_acc #returns train loss and predictions"
      ],
      "id": "yYZbGZ1yLRMd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SND5DFSDLROR"
      },
      "source": [
        "def evaluate():\n",
        "    print(\"\\nEvaluating...\")\n",
        "    Model_2.eval()  # deactivate dropout layers\n",
        "    total_loss = 0\n",
        "    val_total = 0\n",
        "    val_correct = 0\n",
        "\n",
        "    for step,batch in enumerate(val_dataloader):   # iterate over batches\n",
        "        batch = [t.to(device) for t in batch] # push the batch to gpu\n",
        "        x, y, i = batch\n",
        "        \n",
        "        with torch.no_grad(): # deactivate autograd \n",
        "            preds = Model_2(x, y, i)\n",
        "            loss = cross_entropy(preds,y)\n",
        "            total_loss = total_loss + loss.item()\n",
        "            _, predicted = torch.max(preds.data, 1)\n",
        "            val_total += y.size(0)\n",
        "            val_correct += (predicted == y).sum().item()\n",
        "            preds = preds.detach().cpu().numpy()\n",
        "            \n",
        "    avg_loss = total_loss / len(val_dataloader) \n",
        "    val_acc = val_correct/val_total\n",
        "\n",
        "    return avg_loss, val_acc"
      ],
      "id": "SND5DFSDLROR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po-3im5HLRQd",
        "outputId": "c08a9b16-fbd1-4d79-a60d-2b6d5f8f669b"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "best_valid_acc = 0.74\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "train_acces = []\n",
        "val_acces = []\n",
        "\n",
        "for epoch in range(epochs): #for each epoch     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    train_loss, train_acc = train() \n",
        "    valid_loss, val_acc = evaluate() \n",
        "\n",
        "    if val_acc > best_valid_acc: \n",
        "        best_valid_acc = val_acc\n",
        "        torch.save(Model_2.state_dict(), '/content/drive/MyDrive/MSR_data_0910/stage2_saved_weights.pt')\n",
        "    \n",
        "    train_acces.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    val_acces.append(val_acces)\n",
        "    \n",
        "    print('Train acc', np.round(train_acc, 3), 'Val acc', np.round(val_acc, 3))\n",
        "    print('Train loss', np.round(train_loss, 3), 'Val loss', np.round(valid_loss, 3))"
      ],
      "id": "po-3im5HLRQd",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.627 Val acc 0.396\n",
            "Train loss 0.648 Val loss 0.691\n",
            "\n",
            " Epoch 2 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.645 Val acc 0.656\n",
            "Train loss 0.638 Val loss 0.624\n",
            "\n",
            " Epoch 3 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.649 Val acc 0.659\n",
            "Train loss 0.629 Val loss 0.655\n",
            "\n",
            " Epoch 4 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.654 Val acc 0.638\n",
            "Train loss 0.636 Val loss 0.669\n",
            "\n",
            " Epoch 5 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.662 Val acc 0.664\n",
            "Train loss 0.619 Val loss 0.643\n",
            "\n",
            " Epoch 6 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.694 Val acc 0.735\n",
            "Train loss 0.613 Val loss 0.61\n",
            "\n",
            " Epoch 7 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.689 Val acc 0.743\n",
            "Train loss 0.616 Val loss 0.622\n",
            "\n",
            " Epoch 8 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.681 Val acc 0.648\n",
            "Train loss 0.611 Val loss 0.665\n",
            "\n",
            " Epoch 9 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.68 Val acc 0.696\n",
            "Train loss 0.592 Val loss 0.628\n",
            "\n",
            " Epoch 10 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.703 Val acc 0.409\n",
            "Train loss 0.593 Val loss 1.031\n",
            "\n",
            " Epoch 11 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.676 Val acc 0.402\n",
            "Train loss 0.618 Val loss 1.049\n",
            "\n",
            " Epoch 12 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.683 Val acc 0.593\n",
            "Train loss 0.611 Val loss 0.667\n",
            "\n",
            " Epoch 13 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.687 Val acc 0.711\n",
            "Train loss 0.61 Val loss 0.591\n",
            "\n",
            " Epoch 14 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.682 Val acc 0.688\n",
            "Train loss 0.617 Val loss 0.626\n",
            "\n",
            " Epoch 15 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.686 Val acc 0.693\n",
            "Train loss 0.603 Val loss 0.81\n",
            "\n",
            " Epoch 16 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.69 Val acc 0.717\n",
            "Train loss 0.604 Val loss 0.593\n",
            "\n",
            " Epoch 17 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.678 Val acc 0.677\n",
            "Train loss 0.605 Val loss 0.713\n",
            "\n",
            " Epoch 18 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.702 Val acc 0.677\n",
            "Train loss 0.601 Val loss 0.616\n",
            "\n",
            " Epoch 19 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.684 Val acc 0.672\n",
            "Train loss 0.597 Val loss 0.617\n",
            "\n",
            " Epoch 20 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.709 Val acc 0.711\n",
            "Train loss 0.603 Val loss 0.602\n",
            "\n",
            " Epoch 21 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.685 Val acc 0.675\n",
            "Train loss 0.61 Val loss 0.8\n",
            "\n",
            " Epoch 22 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.706 Val acc 0.696\n",
            "Train loss 0.58 Val loss 0.619\n",
            "\n",
            " Epoch 23 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.708 Val acc 0.727\n",
            "Train loss 0.586 Val loss 0.604\n",
            "\n",
            " Epoch 24 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.709 Val acc 0.698\n",
            "Train loss 0.59 Val loss 0.594\n",
            "\n",
            " Epoch 25 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.708 Val acc 0.583\n",
            "Train loss 0.587 Val loss 0.66\n",
            "\n",
            " Epoch 26 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.707 Val acc 0.677\n",
            "Train loss 0.573 Val loss 0.877\n",
            "\n",
            " Epoch 27 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.716 Val acc 0.711\n",
            "Train loss 0.574 Val loss 0.761\n",
            "\n",
            " Epoch 28 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.716 Val acc 0.654\n",
            "Train loss 0.565 Val loss 0.927\n",
            "\n",
            " Epoch 29 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.721 Val acc 0.601\n",
            "Train loss 0.574 Val loss 0.884\n",
            "\n",
            " Epoch 30 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.708 Val acc 0.688\n",
            "Train loss 0.587 Val loss 0.629\n",
            "\n",
            " Epoch 31 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.698 Val acc 0.701\n",
            "Train loss 0.578 Val loss 0.599\n",
            "\n",
            " Epoch 32 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.706 Val acc 0.654\n",
            "Train loss 0.585 Val loss 0.651\n",
            "\n",
            " Epoch 33 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.725 Val acc 0.648\n",
            "Train loss 0.56 Val loss 0.633\n",
            "\n",
            " Epoch 34 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.721 Val acc 0.711\n",
            "Train loss 0.583 Val loss 0.612\n",
            "\n",
            " Epoch 35 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.697 Val acc 0.667\n",
            "Train loss 0.592 Val loss 0.623\n",
            "\n",
            " Epoch 36 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.697 Val acc 0.612\n",
            "Train loss 0.586 Val loss 0.83\n",
            "\n",
            " Epoch 37 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.675 Val acc 0.617\n",
            "Train loss 0.604 Val loss 1.163\n",
            "\n",
            " Epoch 38 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.693 Val acc 0.643\n",
            "Train loss 0.588 Val loss 0.708\n",
            "\n",
            " Epoch 39 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.711 Val acc 0.648\n",
            "Train loss 0.567 Val loss 0.736\n",
            "\n",
            " Epoch 40 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.714 Val acc 0.717\n",
            "Train loss 0.557 Val loss 0.589\n",
            "\n",
            " Epoch 41 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.723 Val acc 0.619\n",
            "Train loss 0.565 Val loss 0.842\n",
            "\n",
            " Epoch 42 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.729 Val acc 0.719\n",
            "Train loss 0.554 Val loss 0.595\n",
            "\n",
            " Epoch 43 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.744 Val acc 0.415\n",
            "Train loss 0.539 Val loss 1.084\n",
            "\n",
            " Epoch 44 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.726 Val acc 0.714\n",
            "Train loss 0.549 Val loss 0.586\n",
            "\n",
            " Epoch 45 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.743 Val acc 0.675\n",
            "Train loss 0.533 Val loss 0.659\n",
            "\n",
            " Epoch 46 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.725 Val acc 0.646\n",
            "Train loss 0.559 Val loss 0.858\n",
            "\n",
            " Epoch 47 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.727 Val acc 0.415\n",
            "Train loss 0.548 Val loss 0.989\n",
            "\n",
            " Epoch 48 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.74 Val acc 0.654\n",
            "Train loss 0.531 Val loss 0.67\n",
            "\n",
            " Epoch 49 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.732 Val acc 0.654\n",
            "Train loss 0.529 Val loss 0.714\n",
            "\n",
            " Epoch 50 / 50\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.749 Val acc 0.606\n",
            "Train loss 0.529 Val loss 1.103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7gTHH995FbE",
        "outputId": "085dc211-710f-44a3-e1cc-48bf0e925da6"
      },
      "source": [
        "path = '/content/drive/MyDrive/MSR_data_0910/0920_stage2_saved_weights.pt'\n",
        "Model_2.load_state_dict(torch.load(path))\n",
        "\n",
        "print('Train_report:')\n",
        "with torch.no_grad():\n",
        "  train_preds = Model_2(train_x.to(device), train_y.to(device), train_i.to(device))\n",
        "  train_preds = train_preds.detach().cpu().numpy()\n",
        "\n",
        "train_preds = np.argmax(train_preds, axis = 1)\n",
        "print(classification_report(train_y, train_preds))\n",
        "\n",
        "print('Val_report:')\n",
        "with torch.no_grad():\n",
        "  val_preds = Model_2(val_x.to(device), val_y.to(device), val_i.to(device))\n",
        "  val_preds = val_preds.detach().cpu().numpy()\n",
        "\n",
        "val_preds = np.argmax(val_preds, axis = 1)\n",
        "print(classification_report(val_y, val_preds))\n",
        "\n",
        "print('Test_report:')\n",
        "with torch.no_grad():\n",
        "  test_preds = Model_2(test_x.to(device), test_y.to(device), test_i.to(device))\n",
        "  test_preds = test_preds.detach().cpu().numpy()\n",
        "\n",
        "test_preds = np.argmax(test_preds, axis = 1)\n",
        "print(classification_report(test_y, test_preds))"
      ],
      "id": "_7gTHH995FbE",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.73      0.71       495\n",
            "           1       0.72      0.70      0.71       505\n",
            "\n",
            "    accuracy                           0.71      1000\n",
            "   macro avg       0.71      0.71      0.71      1000\n",
            "weighted avg       0.71      0.71      0.71      1000\n",
            "\n",
            "Val_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.54      0.63       151\n",
            "           1       0.74      0.87      0.80       230\n",
            "\n",
            "    accuracy                           0.74       381\n",
            "   macro avg       0.74      0.71      0.71       381\n",
            "weighted avg       0.74      0.74      0.73       381\n",
            "\n",
            "Test_report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.54      0.63       151\n",
            "           1       0.74      0.87      0.80       230\n",
            "\n",
            "    accuracy                           0.74       381\n",
            "   macro avg       0.74      0.71      0.71       381\n",
            "weighted avg       0.74      0.74      0.73       381\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtC4K55BDvU1",
        "outputId": "47ef6c90-06c3-4972-a9f5-11210beb2857"
      },
      "source": [
        "val_y_list = val_y.tolist()\n",
        "val_preds_list  = val_preds.tolist()\n",
        "\n",
        "ind_list = list(range(1000, 1381))\n",
        "\n",
        "incorrect_pred = []\n",
        "val_FN = []\n",
        "val_FP = []\n",
        "for i, a, b in zip(ind_list, val_y_list, val_preds_list):\n",
        "  if a != b:\n",
        "    incorrect_pred.append(i)\n",
        "\n",
        "  if (a == 0 and b == 1):\n",
        "    val_FP.append(i)\n",
        "  \n",
        "  if (a == 1 and b == 0):\n",
        "    val_FN.append(i)\n",
        "\n",
        "print(len(incorrect_pred))\n",
        "print(len(val_FP))\n",
        "print(len(val_FN))"
      ],
      "id": "YtC4K55BDvU1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98\n",
            "69\n",
            "29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWqgSxexLWBP",
        "outputId": "dc6539c9-9d75-4026-ee31-c20f2667e4b0"
      },
      "source": [
        "train_y_list = train_y.tolist()\n",
        "train_preds_list  = train_preds.tolist()\n",
        "\n",
        "ind_list = list(range(0, 1000))\n",
        "\n",
        "incorrect_pred_train = []\n",
        "train_FN = []\n",
        "train_FP = []\n",
        "for i, a, b in zip(ind_list, train_y_list, train_preds_list):\n",
        "  if a != b:\n",
        "    incorrect_pred_train.append(i)\n",
        "\n",
        "  if (a == 0 and b == 1):\n",
        "    train_FP.append(i)\n",
        "  \n",
        "  if (a == 1 and b == 0):\n",
        "    train_FN.append(i)\n",
        "\n",
        "print(len(incorrect_pred_train))\n",
        "print(len(train_FP))\n",
        "print(len(train_FN))"
      ],
      "id": "OWqgSxexLWBP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "289\n",
            "135\n",
            "154\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19ZFWJhZFWPh",
        "outputId": "2f5f5d88-2110-416c-943e-de1971940d55"
      },
      "source": [
        "I_tensor_np = I_tensor.cpu().detach().numpy()\n",
        "\n",
        "keyw_doc_list = []\n",
        "for i in range(len(I_tensor_np)):\n",
        "  if 1 in I_tensor_np[i]:\n",
        "    keyw_doc_list.append(1)\n",
        "  else:\n",
        "    keyw_doc_list.append(0)\n",
        "\n",
        "print(len(keyw_doc_list))"
      ],
      "id": "19ZFWJhZFWPh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "zf47tZsHQ_M5",
        "outputId": "409f5a73-84fc-479e-a1b3-bf1c82c73118"
      },
      "source": [
        "keyword_pd = pd.Series(keyw_doc_list)\n",
        "df['keyword'] = keyword_pd \n",
        "df"
      ],
      "id": "zf47tZsHQ_M5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Value</th>\n",
              "      <th>label</th>\n",
              "      <th>keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>10/19/2020\\nSLAVERY AND HUMAN TRAFFICKING\\nINT...</td>\n",
              "      <td>Whistleblower protection (direct employees), W...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Pension\\nProtection\\nFund\\nPension\\nProtection...</td>\n",
              "      <td>Whistleblower protection (direct employees), I...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>10/19/2020\\nModern Slavery &amp; Human\\nTroffickin...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Greene King I MODERN SLAVERY STATEMENT\\nMODERN...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Charles Wells Ltd\\nModern Slavery and Human Tr...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1376</th>\n",
              "      <td>1376</td>\n",
              "      <td>Modern Slavery Act 2015 Statement\\nOur Policy\\...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>1377</td>\n",
              "      <td>Upto 60% off + 20% off ends\\n\\nSearch for\\npro...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1378</th>\n",
              "      <td>1378</td>\n",
              "      <td>Slavery and Human Trafficking Transparency Sta...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1379</th>\n",
              "      <td>1379</td>\n",
              "      <td>Reward Gateway Slavery\\nand Human Trafficking\\...</td>\n",
              "      <td>Hotline (direct employees), Whistleblower prot...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380</th>\n",
              "      <td>1380</td>\n",
              "      <td>Modern Slavery Act Statement\\n– January 2021\\n...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1381 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... keyword\n",
              "0              0  ...       1\n",
              "1              1  ...       1\n",
              "2              2  ...       1\n",
              "3              3  ...       1\n",
              "4              4  ...       1\n",
              "...          ...  ...     ...\n",
              "1376        1376  ...       1\n",
              "1377        1377  ...       1\n",
              "1378        1378  ...       1\n",
              "1379        1379  ...       1\n",
              "1380        1380  ...       1\n",
              "\n",
              "[1381 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgbIrmjBT33A",
        "outputId": "5179a742-352d-4198-a7cd-0f7238084200"
      },
      "source": [
        "df['keyword'].value_counts()"
      ],
      "id": "sgbIrmjBT33A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1077\n",
              "0     304\n",
              "Name: keyword, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cyM4Slh2VTD",
        "outputId": "1ea2ba37-2ac0-4ea6-99c2-9d65f769647f"
      },
      "source": [
        "key1_lb1_train = []\n",
        "key1_lb0_train = []\n",
        "key0_lb1_train = []\n",
        "key0_lb0_train = []\n",
        "\n",
        "for i in list(range(0, 1000)):\n",
        "  if df['keyword'][i] ==1 and df['label'][i] ==1:\n",
        "    key1_lb1_train.append(i)\n",
        "\n",
        "  if df['keyword'][i] ==1 and df['label'][i] ==0:\n",
        "    key1_lb0_train.append(i)\n",
        "\n",
        "  if df['keyword'][i] ==0 and df['label'][i] ==1:\n",
        "    key0_lb1_train.append(i)\n",
        "\n",
        "  if df['keyword'][i] ==0 and df['label'][i] ==0:\n",
        "    key0_lb0_train.append(i)\n",
        "\n",
        "print(len(key1_lb1_train))\n",
        "print(len(key1_lb0_train))\n",
        "print(len(key0_lb1_train))\n",
        "print(len(key0_lb0_train))"
      ],
      "id": "1cyM4Slh2VTD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "442\n",
            "288\n",
            "63\n",
            "207\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Eq3nf422aWe",
        "outputId": "02e9914f-69d6-4b66-a6d9-4a82595b027a"
      },
      "source": [
        "key1_lb1_val = []\n",
        "key1_lb0_val = []\n",
        "key0_lb1_val = []\n",
        "key0_lb0_val = []\n",
        "\n",
        "for i in list(range(1000, 1381)):\n",
        "  if df['keyword'][i] ==1 and df['label'][i] ==1:\n",
        "    key1_lb1_val.append(i)\n",
        "\n",
        "  if df['keyword'][i] ==1 and df['label'][i] ==0:\n",
        "    key1_lb0_val.append(i)\n",
        "\n",
        "  if df['keyword'][i] ==0 and df['label'][i] ==1:\n",
        "    key0_lb1_val.append(i)\n",
        "\n",
        "  if df['keyword'][i] ==0 and df['label'][i] ==0:\n",
        "    key0_lb0_val.append(i)\n",
        "\n",
        "print(len(key1_lb1_val))\n",
        "print(len(key1_lb0_val))\n",
        "print(len(key0_lb1_val))\n",
        "print(len(key0_lb0_val))"
      ],
      "id": "_Eq3nf422aWe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "223\n",
            "124\n",
            "7\n",
            "27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453
        },
        "id": "1A6M6jLzVc0N",
        "outputId": "126faf8c-df9f-439a-bdb6-bf13d041620e"
      },
      "source": [
        "df_val_FP = df.iloc[val_FP]\n",
        "\n",
        "print(len(df_val_FP))\n",
        "\n",
        "count = 0\n",
        "for i in val_FP:\n",
        "  if df_val_FP['keyword'][i] == 1:\n",
        "    count += 1\n",
        "\n",
        "print(count)\n",
        "\n",
        "df_val_FP"
      ],
      "id": "1A6M6jLzVc0N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "69\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Value</th>\n",
              "      <th>label</th>\n",
              "      <th>keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>1005</td>\n",
              "      <td>MENU\\n\\nStock Up on 3/$199\\nSummer Essentials\\...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1023</th>\n",
              "      <td>1023</td>\n",
              "      <td>\\nSearch for...\\n\\n\\n\\n&gt; Modern\\nHome Slaver...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1044</th>\n",
              "      <td>1044</td>\n",
              "      <td>2/25/2021\\n\\nModern Slavery Statement | Allen ...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1059</th>\n",
              "      <td>1059</td>\n",
              "      <td>ATOL\\nprotected\\n\\nPay\\nmonthly\\n\\nFree holida...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1069</th>\n",
              "      <td>1069</td>\n",
              "      <td>Slavery​ ​and​ ​Human​ ​Trafficking​ ​Statemen...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1350</th>\n",
              "      <td>1350</td>\n",
              "      <td>The Rank Group Plc’s Modern Slavery Statement ...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1353</th>\n",
              "      <td>1353</td>\n",
              "      <td>My Favourites\\n\\nMy Swatches\\n\\nLog in\\n\\nMode...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1360</th>\n",
              "      <td>1360</td>\n",
              "      <td>Contact Us\\n\\n+1-502-775-7777\\n\\nCALIFORNIA SU...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1362</th>\n",
              "      <td>1362</td>\n",
              "      <td>Manage my booking\\nLatest Travel Advice\\n\\nHol...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1377</th>\n",
              "      <td>1377</td>\n",
              "      <td>Upto 60% off + 20% off ends\\n\\nSearch for\\npro...</td>\n",
              "      <td>No</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... keyword\n",
              "1005        1005  ...       1\n",
              "1023        1023  ...       1\n",
              "1044        1044  ...       1\n",
              "1059        1059  ...       1\n",
              "1069        1069  ...       1\n",
              "...          ...  ...     ...\n",
              "1350        1350  ...       1\n",
              "1353        1353  ...       1\n",
              "1360        1360  ...       1\n",
              "1362        1362  ...       1\n",
              "1377        1377  ...       1\n",
              "\n",
              "[69 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 982
        },
        "id": "34w19j3KTR6j",
        "outputId": "85b6809b-42e0-4213-a58c-932fda65306e"
      },
      "source": [
        "df_val_FN = df.iloc[val_FN]\n",
        "\n",
        "print(len(df_val_FN))\n",
        "\n",
        "count = 0\n",
        "for i in val_FN:\n",
        "  if df_val_FN['keyword'][i] == 1:\n",
        "    count += 1\n",
        "\n",
        "print(count)\n",
        "\n",
        "df_val_FN"
      ],
      "id": "34w19j3KTR6j",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29\n",
            "23\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Text</th>\n",
              "      <th>Value</th>\n",
              "      <th>label</th>\n",
              "      <th>keyword</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1007</th>\n",
              "      <td>1007</td>\n",
              "      <td>MODERN SLAVERY ACT STATEMENT\\nFERREXPO PLC, FE...</td>\n",
              "      <td>Hotline (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1008</th>\n",
              "      <td>1008</td>\n",
              "      <td>APPE\\n\\nMODERN SLAVERY STATEMENT\\nThis stateme...</td>\n",
              "      <td>Hotline (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1030</th>\n",
              "      <td>1030</td>\n",
              "      <td>About\\n\\nIntercity Express Programme\\n\\nGWML\\n...</td>\n",
              "      <td>Focal Point (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1040</th>\n",
              "      <td>1040</td>\n",
              "      <td>Covid 19, Information &amp; Updates\\n\\n\\n\\n\\n H...</td>\n",
              "      <td>Hotline (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1064</th>\n",
              "      <td>1064</td>\n",
              "      <td>Carclo PLC: Policy on Modern Slavery and Child...</td>\n",
              "      <td>Focal Point (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1091</th>\n",
              "      <td>1091</td>\n",
              "      <td>Prinovis UK Ltd\\nStatement on\\nSlavery and Hum...</td>\n",
              "      <td>Hotline (direct employees), Whistleblower prot...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1092</th>\n",
              "      <td>1092</td>\n",
              "      <td>ENGLISH | LANGUAGE\\n\\nNEWS &amp; MEDIA (HTTPS://NE...</td>\n",
              "      <td>Focal Point (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1116</th>\n",
              "      <td>1116</td>\n",
              "      <td>Eric Wright Group\\nSlavery and Human Trafficki...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1127</th>\n",
              "      <td>1127</td>\n",
              "      <td>MODERN SLAVERY STATEMENT – 2018\\nT&amp;E Ferris LT...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1131</th>\n",
              "      <td>1131</td>\n",
              "      <td>Our Cookie Policy\\nWe are using cookies to giv...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1132</th>\n",
              "      <td>1132</td>\n",
              "      <td>(https://www.lifearc.org)\\nGovernance and stru...</td>\n",
              "      <td>Hotline (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1133</th>\n",
              "      <td>1133</td>\n",
              "      <td>CALIFORNIA TRANSPARENCY IN SUPPLY CHAIN\\nACT D...</td>\n",
              "      <td>Focal Point (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1149</th>\n",
              "      <td>1149</td>\n",
              "      <td>Modern Slavery Act 2015\\nSLAVERY AND HUMAN TRA...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1152</th>\n",
              "      <td>1152</td>\n",
              "      <td>\\n\\nModern Slavery and Human Trafficking Tran...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1157</th>\n",
              "      <td>1157</td>\n",
              "      <td>DocuSign Envelope ID: 5AB3A4DC-A6F8-435C-8CC8-...</td>\n",
              "      <td>Focal Point (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1169</th>\n",
              "      <td>1169</td>\n",
              "      <td>California Transparency in Supply Chains Act (...</td>\n",
              "      <td>Hotline (direct employees), Hotline (supply ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1186</th>\n",
              "      <td>1186</td>\n",
              "      <td>Server Error in '/' Application.\\nThe resource...</td>\n",
              "      <td>Hotline (direct employees), Hotline (supply ch...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1197</td>\n",
              "      <td>DocuSign Envelope ID: 0DA7C961-6C03-46F3-8B38-...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>1253</td>\n",
              "      <td>BES\\nUtilities\\n\\nBES Commercial\\nElectricity\\...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>1258</td>\n",
              "      <td>Modern Slavery and Human Trafficking Statement...</td>\n",
              "      <td>Whistleblower protection (direct employees), W...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1278</th>\n",
              "      <td>1278</td>\n",
              "      <td>Customer\\n\\nYou are here: Home &gt; Strategy, Vis...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1286</th>\n",
              "      <td>1286</td>\n",
              "      <td>Proven Landscape\\nTechnology\\n\\nMenu\\n\\n\\n\\nM...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1317</th>\n",
              "      <td>1317</td>\n",
              "      <td>ERM Modern Slavery\\nStatement 2017\\nNote: This...</td>\n",
              "      <td>Hotline (direct employees), Whistleblower prot...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1324</th>\n",
              "      <td>1324</td>\n",
              "      <td>UK Office &amp; Studio:\\nUnit 1 and 2 Wellesley Co...</td>\n",
              "      <td>Focal Point (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1334</th>\n",
              "      <td>1334</td>\n",
              "      <td>ANTI-SLAVERY AND HUMAN TRAFFICKING POLICY STAT...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1342</th>\n",
              "      <td>1342</td>\n",
              "      <td>RATP Dev London\\nModern Slavery and Human Traf...</td>\n",
              "      <td>Whistleblower protection (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1351</th>\n",
              "      <td>1351</td>\n",
              "      <td>Slavery and Human Trafficking Statement\\nFinan...</td>\n",
              "      <td>Hotline (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1358</th>\n",
              "      <td>1358</td>\n",
              "      <td>Modern Slavery Act 2015\\nThe following stateme...</td>\n",
              "      <td>Focal Point (direct employees)</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1364</th>\n",
              "      <td>1364</td>\n",
              "      <td>Prinovis UK Ltd\\nStatement on\\nSlavery and Hum...</td>\n",
              "      <td>Hotline (direct employees), Whistleblower prot...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  ... keyword\n",
              "1007        1007  ...       1\n",
              "1008        1008  ...       1\n",
              "1030        1030  ...       0\n",
              "1040        1040  ...       1\n",
              "1064        1064  ...       0\n",
              "1091        1091  ...       1\n",
              "1092        1092  ...       1\n",
              "1116        1116  ...       1\n",
              "1127        1127  ...       1\n",
              "1131        1131  ...       1\n",
              "1132        1132  ...       1\n",
              "1133        1133  ...       0\n",
              "1149        1149  ...       1\n",
              "1152        1152  ...       1\n",
              "1157        1157  ...       0\n",
              "1169        1169  ...       1\n",
              "1186        1186  ...       0\n",
              "1197        1197  ...       1\n",
              "1253        1253  ...       1\n",
              "1258        1258  ...       1\n",
              "1278        1278  ...       1\n",
              "1286        1286  ...       1\n",
              "1317        1317  ...       1\n",
              "1324        1324  ...       1\n",
              "1334        1334  ...       0\n",
              "1342        1342  ...       1\n",
              "1351        1351  ...       1\n",
              "1358        1358  ...       1\n",
              "1364        1364  ...       1\n",
              "\n",
              "[29 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Fg197EjxVnh"
      },
      "source": [
        "### Continue training... "
      ],
      "id": "8Fg197EjxVnh"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0bd9CWqxGZV"
      },
      "source": [
        "path1 = '/content/drive/MyDrive/MSR_data_0910/0920_stage2_saved_weights.pt'\n",
        "Model_2 = model_2()\n",
        "Model_2.load_state_dict(torch.load(path1))\n",
        "Model_2 = Model_2.to(device)\n",
        "\n",
        "from torch import optim\n",
        "from transformers import AdamW\n",
        "optimizer = optim.AdamW(Model_2.parameters(), lr = 0.0005, weight_decay=0.01)\n",
        "epochs = 20\n"
      ],
      "id": "b0bd9CWqxGZV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jd3vY-UDxGb3",
        "outputId": "0e8d0c0c-886a-4119-8a2a-4716868975b5"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#best_valid_loss = float('inf')  # set initial loss to infinite\n",
        "\n",
        "best_valid_acc = 0.73\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "train_acces = []\n",
        "val_acces = []\n",
        "\n",
        "for epoch in range(epochs): #for each epoch     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    train_loss, train_acc = train() \n",
        "    valid_loss, val_acc = evaluate() \n",
        "\n",
        "    if val_acc > best_valid_acc: \n",
        "        best_valid_acc = val_acc\n",
        "        torch.save(Model_2.state_dict(), '/content/drive/MyDrive/MSR_data_0910/0920_stage3_saved_weights.pt')\n",
        "    \n",
        "    train_acces.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    val_acces.append(val_acces)\n",
        "    \n",
        "    print('Train acc', np.round(train_acc, 3), 'Val acc', np.round(val_acc, 3))\n",
        "    print('Train loss', np.round(train_loss, 3), 'Val loss', np.round(valid_loss, 3))"
      ],
      "id": "jd3vY-UDxGb3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.702 Val acc 0.591\n",
            "Train loss 0.591 Val loss 0.666\n",
            "\n",
            " Epoch 2 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.679 Val acc 0.717\n",
            "Train loss 0.61 Val loss 0.628\n",
            "\n",
            " Epoch 3 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.692 Val acc 0.499\n",
            "Train loss 0.601 Val loss 0.726\n",
            "\n",
            " Epoch 4 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.687 Val acc 0.402\n",
            "Train loss 0.596 Val loss 0.791\n",
            "\n",
            " Epoch 5 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.708 Val acc 0.407\n",
            "Train loss 0.582 Val loss 0.961\n",
            "\n",
            " Epoch 6 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.7 Val acc 0.696\n",
            "Train loss 0.587 Val loss 0.611\n",
            "\n",
            " Epoch 7 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.707 Val acc 0.685\n",
            "Train loss 0.582 Val loss 0.616\n",
            "\n",
            " Epoch 8 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.71 Val acc 0.486\n",
            "Train loss 0.577 Val loss 0.785\n",
            "\n",
            " Epoch 9 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.716 Val acc 0.402\n",
            "Train loss 0.569 Val loss 1.026\n",
            "\n",
            " Epoch 10 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.714 Val acc 0.57\n",
            "Train loss 0.585 Val loss 0.661\n",
            "\n",
            " Epoch 11 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.722 Val acc 0.74\n",
            "Train loss 0.562 Val loss 0.594\n",
            "\n",
            " Epoch 12 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.727 Val acc 0.428\n",
            "Train loss 0.564 Val loss 0.745\n",
            "\n",
            " Epoch 13 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.719 Val acc 0.409\n",
            "Train loss 0.562 Val loss 1.155\n",
            "\n",
            " Epoch 14 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.723 Val acc 0.672\n",
            "Train loss 0.568 Val loss 0.695\n",
            "\n",
            " Epoch 15 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.704 Val acc 0.415\n",
            "Train loss 0.568 Val loss 0.788\n",
            "\n",
            " Epoch 16 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.72 Val acc 0.407\n",
            "Train loss 0.543 Val loss 1.397\n",
            "\n",
            " Epoch 17 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.712 Val acc 0.596\n",
            "Train loss 0.576 Val loss 0.655\n",
            "\n",
            " Epoch 18 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.728 Val acc 0.643\n",
            "Train loss 0.554 Val loss 0.749\n",
            "\n",
            " Epoch 19 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.71 Val acc 0.425\n",
            "Train loss 0.566 Val loss 0.822\n",
            "\n",
            " Epoch 20 / 20\n",
            "\n",
            "Evaluating...\n",
            "Train acc 0.737 Val acc 0.399\n",
            "Train loss 0.547 Val loss 1.079\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76q_kF8sxGeW"
      },
      "source": [
        "path2 = '/content/drive/MyDrive/MSR_data_0910/0920_stage3_saved_weights.pt'\n",
        "Model_2 = model_2()\n",
        "Model_2.load_state_dict(torch.load(path2))\n",
        "Model_2 = Model_2.to(device)\n",
        "\n",
        "from torch import optim\n",
        "from transformers import AdamW\n",
        "optimizer = optim.AdamW(Model_2.parameters(), lr = 0.00005, weight_decay=0.01)\n",
        "epochs = 20"
      ],
      "id": "76q_kF8sxGeW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWtvtfO98QKV"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "#best_valid_loss = float('inf')  # set initial loss to infinite\n",
        "\n",
        "best_valid_acc = 0.73\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "train_acces = []\n",
        "val_acces = []\n",
        "\n",
        "for epoch in range(epochs): #for each epoch     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "\n",
        "    train_loss, train_acc = train() \n",
        "    valid_loss, val_acc = evaluate() \n",
        "\n",
        "    if val_acc > best_valid_acc: \n",
        "        best_valid_acc = val_acc\n",
        "        torch.save(Model_2.state_dict(), '/content/drive/MyDrive/MSR_data_0910/0920_stage3_saved_weights.pt')\n",
        "    \n",
        "    train_acces.append(train_acc)\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    val_acces.append(val_acces)\n",
        "    \n",
        "    print('Train acc', np.round(train_acc, 3), 'Val acc', np.round(val_acc, 3))\n",
        "    print('Train loss', np.round(train_loss, 3), 'Val loss', np.round(valid_loss, 3))"
      ],
      "id": "QWtvtfO98QKV",
      "execution_count": null,
      "outputs": []
    }
  ]
}
